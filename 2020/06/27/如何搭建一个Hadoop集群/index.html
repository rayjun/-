<!DOCTYPE html>
<html lang="zh-Hans">
<head>
    <title>Rayjun</title>
    <meta name="description" content="https://rayjun.wtf">
    <meta name="keywords" content="程序员,算法,Go,Java,Rayjun,区块链,web3">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta charset="utf-8">
    
        
            
<link rel="stylesheet" href="/css/lemon.css">

        
    
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.slim.min.js"></script>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/styles/default.min.css">
	<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/highlight.min.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-E9HMN12DB9"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-E9HMN12DB9');
      hljs.highlightAll();
     </script>
<meta name="generator" content="Hexo 7.1.1"></head>
<body>
    <div class="menu-outer">
        <div class="container">
			<a class="blog-name" href="/">Rayjun</a>
            <nav class="menu-inner">
                
                    <a class="menu" href="/">首页</a>
                
            <div class="menu nav-search">
                <span>
                    <i class="fa fa-search"></i>
                </span>
                <input type="text" autocomplete="off" name="search" placeholder="搜索" id="local-search-input">
            </div>
            </nav>
        </div>
    </div>

    <div class="content">
        <div class="container">
            <div class="content-left">
                <div class="content-inner">
                    <div id="local-search-result"></div>
                    <div id="div-body">
                    <div class="post">
    <h1>如何搭建一个Hadoop集群</h1>
    <p>在学习大数据系统时，搭建一个 Hadoop 是基本的操作，很多大数据上层的应用都依赖 HDFS，本文介绍一种搭建 Hadoop 集群的方法。</p>
<p>所需软件及环境如下：</p>
<ul>
<li>本地服务器集群</li>
<li>openjdk1.8</li>
<li>hadoop-2.9.2</li>
</ul>
<p>在之前我写过一篇搭建本地服务器集群的方法，如果有需要，可以参考这里搭建一个本地的服务器集群。</p>
<h2 id="环境准备">环境准备</h2>
<p>在开始搭建 Hadoop 之前，还需要做一些准备。</p>
<p>首先，关闭服务器的防火墙，并且禁止开机启动，这样就不用在各个服务器上对端口进行控制。</p>
<pre><code class="language-bash">$ systemctl stop firewalld.service
$ systemctl disable firewalld.service
</code></pre>
<p>然后需要定义一下服务器的 hostname，在集群内，直接使用 hostname 来替代机器进行操作，以 IP 为 192.168.56.3 的服务器为例（这是我的服务器集群的地址，具体看自己集群的 IP 配置）：</p>
<pre><code class="language-bash">$ vi /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=bigdata1
GATEWAY=192.168.56.2
</code></pre>
<p>同样编辑另外两台服务器，起名为 bigdata2 和 bigdata3。</p>
<p>然后编辑各个服务器的 <code>/etc/hosts</code> 文件，添加 hostname 到 IP 的映射：</p>
<pre><code class="language-bash">$ vi /etc/hosts
192.168.56.3 bigdata1
192.168.56.4 bigdata2
192.168.56.5 bigdata3
</code></pre>
<p>最后，为了在宿主机上可以方便的访问各个服务器，同样也要编辑宿主机的 hosts 文件：</p>
<pre><code class="language-bash">$ vi /etc/hosts

192.168.56.3 bigdata1
192.168.56.4 bigdata2
192.168.56.5 bigdata3
</code></pre>
<p>到这里，服务器集群的配置就完成了，接下来就开始配置 Hadoop 环境。</p>
<p>Hadoop 也依赖 Java 环境，所以首先需要配置 JDK，本文使用的是 openjdk1.8。</p>
<p>本文所有的软件都会安装到 <code>/opt/module</code> 目录下，如果没有这个目录，创建一个。</p>
<pre><code class="language-bash">$ mkdir /opt/module
</code></pre>
<p>可以将下载好的 jdk 通过 scp 命令从宿主机拷贝到 服务器，然后解压到目标目录：</p>
<pre><code class="language-bash">$ tar -zxvf openjdk-8u41-b04-linux-x64-14_jan_2020.tar.gz -C /opt/module/
</code></pre>
<p>解压完成后再配置环境变量：</p>
<pre><code class="language-bash">$ vi /etc/profile

#Java config
export JAVA_HOME=/opt/module/java-se-8u41-ri
export PATH=$PATH:$JAVA_HOME/bin
</code></pre>
<pre><code class="language-bash">$ source /etc/profile
</code></pre>
<pre><code class="language-bash">$ java -version

Openjdk version &quot;1.8.0_41&quot;
OpenJDK Runtime Environment (build 1.8.0_41-b04)
OpenJDK 64-Bit Server VM (build 25.40-b25, mixed mode)
</code></pre>
<p>JDK 配置完成。</p>
<p>然后同样将 scp 命令将 hadoop 安装包拷贝到服务器，解压到 /opt/module 目录中：</p>
<pre><code class="language-bash">$ tar -zxvf hadoop-2.9.2.tar.gz -C /opt/module/
</code></pre>
<p>同样配置环境目录</p>
<pre><code class="language-bash">$ vi /etc/profile
#Hadoop config
export HADOOP_HOME=/opt/module/hadoop-2.9.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
</code></pre>
<pre><code class="language-bash">$ source /etc/profile
</code></pre>
<pre><code class="language-bash">$ hadoop version
Hadoop 2.9.2
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704
Compiled by ajisaka on 2018-11-13T12:42Z
Compiled with protoc 2.5.0
From source with checksum 3a9939967262218aa556c684d107985
This command was run using /opt/module/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar
</code></pre>
<p>hadoop 的安装完成，到这里，单台机器的软件已经安装完成。</p>
<p>如果每台机器都要这样配置就太繁琐了，可以利用 rsync 将安装好的软件直接拷贝到其他的机器，这里当然也可以使用 scp 命令进行拷贝，但是 scp 命令每次都是全量拷贝，在文件很多时，拷贝的速度会很慢，而 rsync 是增量拷贝，只拷贝那些被修改了的文件，所以拷贝的速度会很快。</p>
<p>如果系统上，没有这个软件，就使用以下命令进行安装：</p>
<pre><code class="language-bash">$ yum install rsync
</code></pre>
<p>安装完成后利用 rsync 将安装好的软件同步到另外两台服务器：</p>
<pre><code class="language-bash">$ rsync -rvl /opt/module/ root@bigdata2:/opt/module
$ rsync -rvl /opt/module/ root@bigdata3:/opt/module
</code></pre>
<p>然后分别配置环境变量（其实 /etc/profile 文件也可以被同步到另外的服务器，这里为了演示，就没有直接同步过去）：</p>
<pre><code class="language-bash">$ vi /etc/profile
#Java config
export JAVA_HOME=/opt/module/java-se-8u41-ri
export PATH=$PATH:$JAVA_HOME/bin

#Hadoop config
export HADOOP_HOME=/opt/module/hadoop-2.9.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
</code></pre>
<pre><code class="language-bash">$ source /etc/profile
</code></pre>
<p>到这里，所有软件安装完成。</p>
<h2 id="集群规划">集群规划</h2>
<p>基础环境配置完成后，需要对集群中服务器做规划，让每台服务器承担不同的角色。</p>
<p>具体规划如下，最重要的 NameNode 放在第一台服务器上，yarn 的 ResourceManager 放在 第二台服务器上，SecondaryNamenode 则放在第三台服务器上。</p>
<p>具体规划如下：</p>
<p><img src="jiqunguihua.jpg" alt=""></p>
<h2 id="集群配置">集群配置</h2>
<p>然后就可以根据上面的规划来配置集群，以 IP 为 192.168.56.3 的服务器为例。</p>
<p>Hadoop 的所有配置文件都在 <code>etc/hadoop</code> 目录下：</p>
<pre><code class="language-bash">$ cd /opt/module/hadoop-2.9.2/etc/hadoop
</code></pre>
<p>首先配置 Hadoop 的核心文件，打开 <code>core-site.xml</code>，添加如下配置，确定 NameNode 所在的服务器：</p>
<pre><code class="language-bash">$ vi core-site.xml

&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://bigdata1:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/opt/module/hadoop-2.9.2/data/tmp&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>然后打开 <code>[hadoop-env.sh](http://hadoop-env.sh)</code> 配置 JDK:</p>
<pre><code class="language-bash">$ vi hadoop-env.sh

export JAVA_HOME=/opt/module/java-se-8u41-ri/
</code></pre>
<p>然后接着配置 HDFS 相关，配置每个文件的保存的份数，同时配置 SecondaryNameNode 所在的服务器，编辑 <code>hdfs-site.xml</code>文件:</p>
<pre><code class="language-bash">$ vi hdfs-site.xml

&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
    &lt;value&gt;bigdata3:50090&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>然后就开始配置 yarn：</p>
<pre><code class="language-bash">$ vi yarn-env.sh
export JAVA_HOME=/opt/module/java-se-8u41-ri/
</code></pre>
<p>确定mapreduce 所用的算法，以及确定 ResourceManager 所在的服务器，编辑 <code>yarn-site.xml</code>:</p>
<pre><code class="language-bash">$ vi yarn-site.xml
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;bigdata2&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>然后配置一下 mapreduce:</p>
<pre><code class="language-bash">$ vi mapred-env.sh
export JAVA_HOME=/opt/module/java-se-8u41-ri/
</code></pre>
<p>配置 mapreduce 任务在通过 yarn 来调度：</p>
<pre><code class="language-bash">$ cp mapred-site.xml.template mapred-site.xml
$ vi mapred-site.xml
&lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>最后还要做一个集群的配置，让各个服务器知道这个集群中有哪些服务器：</p>
<pre><code class="language-bash">$ vi slaves
bigdata1
bigdata2
bigdata3
</code></pre>
<p>然后将配置同步到另外两台机器：</p>
<pre><code class="language-bash">$ rsync -rvl /opt/module/hadoop-2.9.2/ root@bigdata2:/opt/module/hadoop-2.9.2
$ rsync -rvl /opt/module/hadoop-2.9.2/ root@bigdata3:/opt/module/hadoop-2.9.2
</code></pre>
<p>所有的配置到这里就完成了。</p>
<h2 id="集群操作">集群操作</h2>
<p>接下来启动集群，首次启动集群需要对 NameNode 进行格式化：</p>
<pre><code class="language-bash">$ cd /opt/module/hadoop-2.9.2
$ bin/hdfsnamenode-format
</code></pre>
<p>然后启动 hdfs，要在第一台服务器(IP: 192.168.56.3) 上启动：</p>
<pre><code class="language-bash">$ sbin/start-dfs.sh
</code></pre>
<p>然后启动 yarn，在第二台服务器（IP：192.168.56.4）上启动：</p>
<pre><code class="language-bash">$ sbin/start-yarn.sh
</code></pre>
<p>然后访问 <a href="http://192.168.56.5:50090/%EF%BC%8C%E5%A6%82%E6%9E%9C%E7%9C%8B%E5%88%B0%E5%A6%82%E4%B8%8B%E7%9A%84%E7%9A%84%E7%95%8C%E9%9D%A2%EF%BC%8C%E8%AF%B4%E6%98%8E%E9%9B%86%E7%BE%A4%E5%B0%B1%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F%E4%BA%86%E3%80%82">http://192.168.56.5:50090/，如果看到如下的的界面，说明集群就启动成功了。</a></p>
<p><img src="hadoop.png" alt=""></p>
<p>停止集群时通过如下命令停止就可以了：</p>
<pre><code class="language-bash">$ sbin/stop-yarn.sh
$ sbin/stop-dfs.sh
</code></pre>
<p>文 / Rayjun</p>

</div>

                    </div>
                </div>
            </div>
            <!--<div class="content-right">
                <div class="context-box">
                    <div class="wechat">
    <div class="header">
        <img src="/images/wechat.jpeg">
    </div>
</div>
                </div>
			</div> -->
        </div>
    </div>
    <div class="bottom-outer">
        <div class="bottom-inner">
            <span>©2024 Rayjun</span>
            <span>&nbsp;&nbsp; PowerBy <a href="https://hexo.io/">Hexo</a></span>
        </div>
    </div>

    
        
        
<script src="/js/lemon.js"></script>

        
	
</body>
</html>
